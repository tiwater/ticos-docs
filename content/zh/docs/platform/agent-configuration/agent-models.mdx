# 模型配置

模型配置页面允许您为智能体选择和配置底层的大语言模型（LLM）。这些设置直接决定了智能体的核心能力，例如逻辑推理、工具使用和视觉理解。

## 基本设置

此部分用于选择驱动智能体的基础模型。

- **服务商**: 在这里选择提供大语言模型的服务商。目前支持的服务商包括 **OpenAI** 等。
- **模型**: 根据选择的服务商，从下拉列表中选择一个具体的模型版本，例如 `gpt-4o-2024-08-06`。模型名称下方的说明会提示该模型所支持的特定功能，如文件上传和函数调用。

## 模型能力

选择要为此模型启用的模态。只能选择支持的模态。

- **文本**: 处理和生成对话和内容创作的文本响应。
- **音频**: 处理语音识别和音频生成功能。
- **图像**: 使用AI辅助处理、分析和生成图像。
- **视频**: 处理视频内容的分析和生成。

## 工作模式

配置您的智能体与客户端交互的方式。

- **实时模式**: 选择本智能体的工作模式，是实时（Realtime）模式还是标准 Restful API 模式。实时模式提供连续交互体验，而 Restful API 模式使用标准的请求-响应模式。

## 身份验证

此部分用于配置访问模型服务所需的 API 密钥。

- **使用自定义 API 密钥**:
  - **关闭状态**: 默认情况下，平台会使用自身的密钥。这有助于优化成本并可能提供额外的功能。
  - **开启状态**: 您也可以选择开启此开关，然后在下方的输入框中填入您自己的 API 密钥。

## 高级设置

高级设置提供了对模型行为进行微调的参数。

- **指令 (Instructions)**: 在此文本框中输入系统级指令（System Prompt）。这些指令将为智能体设定一个角色、背景和行为准则，引导其以特定的风格或遵循特定的逻辑进行回应。
- **温度 (Temperature)**: 通过拖动滑块或直接输入数值（0-1）来设置。较高的值（如 0.8）会使模型输出更具创造性和随机性，而较低的值（如 0.2）则会使其输出更加确定和专注。
- **最大响应字符数 (Max Response Tokens)**: 设置模型单次回复所能生成的最大字符数（Token）。这有助于控制响应的长度和API成本。
- **上下文轮数 (Context Turns)**: 设定智能体在对话中能够记忆的上下文轮数（范围 4-20）。更多的轮数意味着智能体能“记住”更早的对话内容。
- **工具选择策略 (Tool Choice Strategy)**: 配置模型在需要使用工具时的决策方式，例如“自动”决定或强制调用某个特定工具。
- **记忆生成 (Memory Generation)**: 配置与智能体记忆相关的生成策略。

## 语音情感引擎

此部分用于配置与语音输出相关的情感表现。

- **情感引擎**: 选择一个情感引擎后，智能体将能够根据对话的上下文和用户的情感，自动切换其播报语音的声线和情感，使交互更加生动自然。
